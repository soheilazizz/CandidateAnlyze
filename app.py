import os
import io
from datetime import date
from pathlib import Path

import streamlit as st
from openai import OpenAI

# --------- Helpers: extract text ----------
def extract_text_from_upload(uploaded_file) -> str:
    name = uploaded_file.name.lower()

    if name.endswith(".txt"):
        return uploaded_file.getvalue().decode("utf-8", errors="ignore")

    if name.endswith(".pdf"):
        from pypdf import PdfReader
        reader = PdfReader(io.BytesIO(uploaded_file.getvalue()))
        parts = []
        for page in reader.pages:
            parts.append(page.extract_text() or "")
        return "\n".join(parts)

    if name.endswith(".docx"):
        from docx import Document
        tmp = io.BytesIO(uploaded_file.getvalue())
        doc = Document(tmp)
        return "\n".join([p.text for p in doc.paragraphs])

    raise ValueError("ÙØ±Ù…Øª Ø±Ø²ÙˆÙ…Ù‡/JD Ø¨Ø§ÛŒØ¯ ÛŒÚ©ÛŒ Ø§Ø² pdf/docx/txt Ø¨Ø§Ø´Ø¯.")


def transcribe_audio_bytes(file_bytes: bytes, filename: str) -> str:
    api_key = os.getenv("AVALAI_API_KEY")
    if not api_key:
        raise RuntimeError("AVALAI_API_KEY Ø¯Ø± Secrets Ø³Øª Ù†Ø´Ø¯Ù‡.")

    client = OpenAI(base_url="https://api.avalai.ir/v1", api_key=api_key)

    # Ù…ÙˆÙ‚Øª Ø±ÙˆÛŒ Ø¯ÛŒØ³Ú© (Ø¨Ø±Ø§ÛŒ SDK)
    tmp_path = Path("/tmp") / filename
    tmp_path.write_bytes(file_bytes)

    try:
        with open(tmp_path, "rb") as f:
            t = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="text",
                language="fa",
            )
        return str(t)
    finally:
        try:
            tmp_path.unlink(missing_ok=True)
        except Exception:
            pass


def generate_report(resume_text: str, jd_text: str, interview_asr: str) -> str:
    api_key = os.getenv("AVALAI_API_KEY")
    client = OpenAI(base_url="https://api.avalai.ir/v1", api_key=api_key)

    SYSTEM = "You are a strict, evidence-based HR & business strategy interviewer. Be concise and avoid fluff."

    ASR_NOTE_FA = """
Ù…ØªÙ† Ù…ØµØ§Ø­Ø¨Ù‡ Ø²ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ Ø®Ø§Ù… ØªØ¨Ø¯ÛŒÙ„ Ú¯ÙØªØ§Ø± Ø¨Ù‡ Ù…ØªÙ† (ASR) Ø§Ø³Øª Ùˆ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø´Ø§Ù…Ù„ ØºÙ„Ø· Ø§Ù…Ù„Ø§ÛŒÛŒØŒ
Ø´Ú©Ø³Øª Ú©Ù„Ù…Ø§ØªØŒ ØªÚ©Ø±Ø§Ø±ØŒ ÛŒØ§ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù†Ú¯Ø§Ø±Ø´ÛŒ Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ù†Ø§Ø´ÛŒ Ø§Ø² Ø³ÛŒØ³ØªÙ… ASR Ø§Ø³Øª Ù†Ù‡ ÙØ±Ø¯ Ù…ØµØ§Ø­Ø¨Ù‡â€ŒØ´ÙˆÙ†Ø¯Ù‡.
Ú©ÛŒÙÛŒØª Ø²Ø¨Ø§Ù†/Ø§Ù…Ù„Ø§ Ø±Ø§ Ù…Ø¹ÛŒØ§Ø± Ù‚Ø¶Ø§ÙˆØª Ù‚Ø±Ø§Ø± Ù†Ø¯Ù‡. Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ø±Ø§ Ù†ÙˆÛŒØ² ÙØ±Ø¶ Ú©Ù†.
"""

    FORMAT_SPEC = f"""
Ú¯Ø²Ø§Ø±Ø´ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§ â€” Ù†Ø³Ø®Ù‡ ÛŒÚ©â€ŒØµÙØ­Ù‡â€ŒØ§ÛŒ (ÙØ§Ø±Ø³ÛŒ)

Ù‚Ø§Ù„Ø¨ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ø´Ù…Ø§Ø±Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø­ÙØ¸ Ø´ÙˆØ¯:

Ù†Ø§Ù… Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§: (Ø§Ø² Ø±Ø²ÙˆÙ…Ù‡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†Ø› Ø§Ú¯Ø± Ù†Ø¨ÙˆØ¯ Ø¨Ù†ÙˆÛŒØ³ "Ù†Ø§Ù…Ø´Ø®Øµ")
Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„: (Ø§Ø² JD Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†)
ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´: {date.today().strftime("%Y-%m-%d")}
Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø±Ø±Ø³ÛŒ: Ø±Ø²ÙˆÙ…Ù‡ + ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù…ØµØ§Ø­Ø¨Ù‡ (Ø®Ø±ÙˆØ¬ÛŒ ASR)

1) Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ
- Ø§Ù…ØªÛŒØ§Ø² ØªÙ†Ø§Ø³Ø¨ Ú©Ù„ÛŒ (Fit Score): XX/100 | Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: Ú©Ù…/Ù…ØªÙˆØ³Ø·/Ø¨Ø§Ù„Ø§
- Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Yes / No / Maybe (Ù…Ø´Ø±ÙˆØ·/ØºÛŒØ±Ù…Ø´Ø±ÙˆØ·)
- Ú†Ø±Ø§ Ù…Ø«Ø¨ØªØŸ (Û²-Û³ Ø¬Ù…Ù„Ù‡)
- Ø±ÛŒØ³Ú© Ø§ØµÙ„ÛŒ: (Û±-Û² Ø¬Ù…Ù„Ù‡)

2) Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ú©Ù„ÛŒØ¯ÛŒ (Strengths)

3) Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù / Ø±ÛŒØ³Ú©â€ŒÙ‡Ø§ (Weaknesses & Risks)

4) ØªØ­Ù„ÛŒÙ„ ØªÙ†Ø§Ø³Ø¨ Ù…Ù‡Ø§Ø±ØªÛŒ (Resume vs JD)
- Must-have Ù‡Ø§ (Ú©Ù„ÛŒØ¯ÛŒ): ÛŒÚ© Ø¬Ø¯ÙˆÙ„ 3 Ø³ØªÙˆÙ†Ù‡ Ø¨Ø§ Ø³Ø±ÙØµÙ„â€ŒÙ‡Ø§ÛŒ:
  Ù†ÛŒØ§Ø² Ø´ØºÙ„ÛŒ | Ø´ÙˆØ§Ù‡Ø¯ Ø§Ø² Ø±Ø²ÙˆÙ…Ù‡/Ù…ØµØ§Ø­Ø¨Ù‡ | Ù…ÛŒØ²Ø§Ù† ØªØ·Ø§Ø¨Ù‚ (Ù¾Ø§ÛŒÛŒÙ†/Ù…ØªÙˆØ³Ø·/Ø¨Ø§Ù„Ø§)
- Ø´Ú©Ø§Ùâ€ŒÙ‡Ø§ (Gaps): 2 ØªØ§ 4 Ù…ÙˆØ±Ø¯ Ø¨Ø§ Impact: Low/Medium/High

5) ØªØ­Ù„ÛŒÙ„ Ù…ØµØ§Ø­Ø¨Ù‡ (Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø¨Ú© Ú©Ø§Ø±ÛŒ Ø§Ø² Ù„Ø­Ù† Ùˆ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§)
- Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø®â€ŒÚ¯ÙˆÛŒÛŒ/Ø´ÙØ§ÙÛŒØª/Ù…Ø§Ù„Ú©ÛŒØª/Ø±ÛŒØ³Ú©â€ŒÙ‡Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø·ÛŒ + Ø¯Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡
- Ù†Ù…ÙˆÙ†Ù‡ Ø´ÙˆØ§Ù‡Ø¯: Ø¯Ùˆ Quote Ú©ÙˆØªØ§Ù‡

6) Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø§Ø¯Ø¹Ø§Ù‡Ø§ (Resume vs Interview)
7) Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ± Ø¨Ø¹Ø¯ (Ø³ÙˆØ§Ù„Ø§Øª Ù‡Ø¯ÙÙ…Ù†Ø¯)
8) Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ

Ù…Ø¨Ù†Ø§ÛŒ Fit Score Ø±Ø§ ØµØ±ÛŒØ­ Ùˆ Ø³Ø§Ø¯Ù‡ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡:
- Ú†Ù‡Ø§Ø± Ù…Ø¹ÛŒØ§Ø±: Ø¯Ø±Ú© Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©ØŒ ØªØ­Ù„ÛŒÙ„ Ùˆ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒØŒ Ù†Ú¯Ø§Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒØŒ Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙØªØ§Ø±ÛŒ
- Ø´ÙˆØ§Ù‡Ø¯ Ù‡Ø± Ù…Ø¹ÛŒØ§Ø± Ø±Ø§ Ø°Ú©Ø± Ú©Ù† Ùˆ Ø¨Ú¯Ùˆ Ú†Ø±Ø§ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§/Ù¾Ø§ÛŒÛŒÙ† Ø´Ø¯Ù‡.
"""

    prompt = f"""
{FORMAT_SPEC}

Ù‚ÙˆØ§Ù†ÛŒÙ† Ø­ÛŒØ§ØªÛŒ:
- ÙÙ‚Ø· Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† Ø³Ù‡ ÙˆØ±ÙˆØ¯ÛŒ Ù‚Ø¶Ø§ÙˆØª Ú©Ù†: JDØŒ Ø±Ø²ÙˆÙ…Ù‡ØŒ Ù…ØªÙ† Ù…ØµØ§Ø­Ø¨Ù‡
- Ù…ØªÙ† Ù…ØµØ§Ø­Ø¨Ù‡ ASR Ø®Ø§Ù… Ø§Ø³Øª: {ASR_NOTE_FA}
- Ø§Ø² Ø´Ø¹Ø§Ø± Ø¯ÙˆØ±ÛŒ Ú©Ù†Ø› Ø´ÙˆØ§Ù‡Ø¯ Ú©ÙˆØªØ§Ù‡ Ø¨Ø¯Ù‡.
- Ø§Ú¯Ø± Ú†ÛŒØ²ÛŒ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù†ÛŒØ³ØªØŒ "Ù†Ø§Ù…Ø´Ø®Øµ/ÛŒØ§ÙØª Ù†Ø´Ø¯" Ø¨Ù†ÙˆÛŒØ³.

[JD]
{jd_text}

[RESUME]
{resume_text}

[INTERVIEW_ASR]
{interview_asr}
"""

    resp = client.chat.completions.create(
        model=os.getenv("AVALAI_TEXT_MODEL", "gpt-4o-mini"),
        messages=[
            {"role": "system", "content": SYSTEM},
            {"role": "user", "content": prompt},
        ],
        temperature=0.3,
    )
    return resp.choices[0].message.content


def report_to_docx_bytes(report_text: str) -> bytes:
    from docx import Document
    from docx.shared import Pt
    from docx.enum.text import WD_ALIGN_PARAGRAPH

    doc = Document()

    def add_rtl(text, bold=False, size=11):
        p = doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.RIGHT
        r = p.add_run(text)
        r.bold = bold
        r.font.size = Pt(size)

    add_rtl("Ú¯Ø²Ø§Ø±Ø´ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§ â€” Ù†Ø³Ø®Ù‡ ÛŒÚ©â€ŒØµÙØ­Ù‡â€ŒØ§ÛŒ", bold=True, size=14)
    doc.add_paragraph("")

    # Ø³Ø§Ø¯Ù‡: Ø®Ø· Ø¨Ù‡ Ø®Ø·
    for line in report_text.splitlines():
        line = line.strip()
        if not line:
            doc.add_paragraph("")
            continue
        is_section = any(line.startswith(f"{k})") for k in range(1, 9))
        is_meta = line.startswith("Ù†Ø§Ù… Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§") or line.startswith("Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„") or line.startswith("ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´") or line.startswith("Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø±Ø±Ø³ÛŒ")
        if is_section:
            add_rtl(line, bold=True, size=12)
        elif is_meta:
            add_rtl(line, bold=True, size=11)
        else:
            add_rtl(line, bold=False, size=11)

    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()


# --------- UI ----------
st.set_page_config(page_title="Candidate Evaluator (FA)", page_icon="ğŸ§ ", layout="centered")
st.title("ğŸ§  Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§ Ø§Ø² Ø±ÙˆÛŒ Ù…ØµØ§Ø­Ø¨Ù‡ + Ø±Ø²ÙˆÙ…Ù‡ + Ø¢Ú¯Ù‡ÛŒ Ø´ØºÙ„ÛŒ")

st.caption("Ø¢Ù¾Ù„ÙˆØ¯ Û³ ÙØ§ÛŒÙ„ â†’ ØªØ¨Ø¯ÛŒÙ„ Ú¯ÙØªØ§Ø± Ø¨Ù‡ Ù…ØªÙ† â†’ ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ â†’ Ø®Ø±ÙˆØ¬ÛŒ Word")

audio = st.file_uploader("ÙØ§ÛŒÙ„ ØµÙˆØª/ÙˆÛŒØ¯Ø¦Ùˆ Ù…ØµØ§Ø­Ø¨Ù‡", type=["mp3","wav","m4a","mp4","mpeg","mpga","ogg","oga","webm","flac"])
resume = st.file_uploader("Ø±Ø²ÙˆÙ…Ù‡ (pdf/docx/txt)", type=["pdf","docx","txt"])
jd = st.file_uploader("Ø¢Ú¯Ù‡ÛŒ Ø´ØºÙ„ÛŒ (pdf/docx/txt)", type=["pdf","docx","txt"])

if st.button("ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´"):
    if not (audio and resume and jd):
        st.error("Ù‡Ø± Û³ ÙØ§ÛŒÙ„ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†.")
        st.stop()

    with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†..."):
        interview_text = transcribe_audio_bytes(audio.getvalue(), audio.name)

    with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø±Ø²ÙˆÙ…Ù‡ Ùˆ JD..."):
        resume_text = extract_text_from_upload(resume)
        jd_text = extract_text_from_upload(jd)

    with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ..."):
        report_text = generate_report(resume_text, jd_text, interview_text)

    st.success("Ú¯Ø²Ø§Ø±Ø´ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")
    st.text_area("Ø®Ø±ÙˆØ¬ÛŒ Ú¯Ø²Ø§Ø±Ø´", report_text, height=420)

    docx_bytes = report_to_docx_bytes(report_text)
    st.download_button(
        "Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú¯Ø²Ø§Ø±Ø´ Word",
        data=docx_bytes,
        file_name="candidate_report.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    )
