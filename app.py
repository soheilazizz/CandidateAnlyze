import os
import io
import re
import html
import base64
from datetime import date
from pathlib import Path
from urllib.parse import urlparse

import streamlit as st
from openai import OpenAI

# =========================
# Page config + icon
# =========================
ICON_PATH = "assets/icon.png"
if Path(ICON_PATH).exists():
    st.set_page_config(page_title="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§", page_icon=ICON_PATH, layout="wide")
else:
    st.set_page_config(page_title="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§", page_icon="ğŸ§¾", layout="wide")

# =========================
# Font embedding (Vazirmatn) + RTL CSS
# =========================
def load_font_b64(path: str) -> str:
    return base64.b64encode(Path(path).read_bytes()).decode()

css_font_faces = ""
reg_path = Path("assets/Vazirmatn-Regular.ttf")
bold_path = Path("assets/Vazirmatn-Bold.ttf")

if reg_path.exists() and bold_path.exists():
    REG = load_font_b64(str(reg_path))
    BOLD = load_font_b64(str(bold_path))
    css_font_faces = f"""
    @font-face {{
      font-family: 'FA';
      src: url(data:font/ttf;base64,{REG}) format('truetype');
      font-weight: 400;
      font-style: normal;
    }}
    @font-face {{
      font-family: 'FA';
      src: url(data:font/ttf;base64,{BOLD}) format('truetype');
      font-weight: 700;
      font-style: normal;
    }}
    """

st.markdown(f"""
<style>
{css_font_faces}

:root {{
  --bg: #0b1220;
  --card: rgba(255,255,255,0.06);
  --border: rgba(255,255,255,0.12);
  --text: rgba(255,255,255,0.93);
  --muted: rgba(255,255,255,0.75);
}}

html, body, [class*="css"] {{
  font-family: {'FA' if css_font_faces else 'system-ui'}, -apple-system, Segoe UI, Roboto, Arial, sans-serif !important;
  direction: rtl;
  text-align: right;
  line-height: 2.05;
  font-size: 15.5px;
  color: var(--text);
  unicode-bidi: plaintext;
}}

h1,h2,h3 {{
  letter-spacing: 0 !important;
  line-height: 1.5;
}}

.card {{
  background: var(--card);
  border: 1px solid var(--border);
  padding: 18px 18px;
  border-radius: 16px;
}}

.small {{
  font-size: 0.92rem;
  color: var(--muted);
}}

hr {{
  border: none;
  height: 1px;
  background: var(--border);
  margin: 16px 0;
}}

.stButton>button {{
  border-radius: 12px;
  padding: 10px 16px;
  font-weight: 700;
}}

.report {{
  direction: rtl;
  text-align: right;
  unicode-bidi: plaintext;
  line-height: 2.05;
  font-size: 15.5px;
}}

.report p {{
  margin: 0 0 10px 0;
}}

.report table {{
  width: 100%;
  border-collapse: collapse !important;
  margin: 10px 0 16px 0;
}}

.report th, .report td {{
  border: 1px solid rgba(255,255,255,0.28) !important;
  padding: 10px 10px !important;
  vertical-align: top !important;
  text-align: right !important;
}}

.report thead th {{
  background: rgba(255,255,255,0.08);
  font-weight: 700;
}}

.ltr {{
  direction: ltr;
  unicode-bidi: embed;
  display: inline-block;
  text-align: left;
}}
</style>
""", unsafe_allow_html=True)

# =========================
# Helpers: Markdown table parsing
# =========================
def is_md_table_line(line: str) -> bool:
    s = line.strip()
    return s.startswith("|") and s.endswith("|") and s.count("|") >= 3

def is_md_separator(line: str) -> bool:
    s = line.strip().replace(" ", "")
    return s.startswith("|") and set(s.replace("|", "")) <= set("-:")

def parse_md_table(lines):
    header = [c.strip() for c in lines[0].strip().strip("|").split("|")]
    rows = []
    for ln in lines[2:]:
        cols = [c.strip() for c in ln.strip().strip("|").split("|")]
        if len(cols) < len(header):
            cols += [""] * (len(header) - len(cols))
        rows.append(cols[:len(header)])
    return header, rows

latin_chunk = re.compile(r'([A-Za-z0-9][A-Za-z0-9\-\._/+# ]{0,50})')

def wrap_ltr(text: str) -> str:
    safe = html.escape(text)
    return latin_chunk.sub(r'<span class="ltr">\1</span>', safe)

def markdown_to_html_with_tables(md: str) -> str:
    lines = md.splitlines()
    out = []
    i = 0
    while i < len(lines):
        line = lines[i].rstrip("\n")
        s = line.strip()

        # table block
        if is_md_table_line(s) and i + 1 < len(lines) and is_md_separator(lines[i+1]):
            block = [s, lines[i+1].strip()]
            j = i + 2
            while j < len(lines) and is_md_table_line(lines[j].strip()):
                block.append(lines[j].strip())
                j += 1

            headers, rows = parse_md_table(block)
            out.append("<table><thead><tr>" + "".join(f"<th>{wrap_ltr(h)}</th>" for h in headers) + "</tr></thead><tbody>")
            for r in rows:
                out.append("<tr>" + "".join(f"<td>{wrap_ltr(c)}</td>" for c in r) + "</tr>")
            out.append("</tbody></table>")
            i = j
            continue

        # normal text
        if s:
            out.append(f"<p>{wrap_ltr(s)}</p>")
        else:
            out.append("<div style='height:6px'></div>")
        i += 1

    return "<div class='report'>" + "\n".join(out) + "</div>"

# =========================
# Helpers: Extract resume/JD text
# =========================
def extract_text_from_upload(uploaded_file) -> str:
    name = uploaded_file.name.lower()

    if name.endswith(".txt"):
        return uploaded_file.getvalue().decode("utf-8", errors="ignore")

    if name.endswith(".pdf"):
        from pypdf import PdfReader
        reader = PdfReader(io.BytesIO(uploaded_file.getvalue()))
        parts = []
        for page in reader.pages:
            parts.append(page.extract_text() or "")
        return "\n".join(parts)

    if name.endswith(".docx"):
        from docx import Document
        tmp = io.BytesIO(uploaded_file.getvalue())
        doc = Document(tmp)
        return "\n".join([p.text for p in doc.paragraphs])

    raise ValueError("ÙØ±Ù…Øª Ø±Ø²ÙˆÙ…Ù‡/JD Ø¨Ø§ÛŒØ¯ ÛŒÚ©ÛŒ Ø§Ø² pdf/docx/txt Ø¨Ø§Ø´Ø¯.")

# =========================
# AvalAI calls
# =========================
def transcribe_audio_bytes(file_bytes: bytes, filename: str) -> str:
    api_key = os.getenv("AVALAI_API_KEY")
    if not api_key:
        raise RuntimeError("Ú©Ù„ÛŒØ¯ AVALAI_API_KEY Ø¯Ø± Secrets Ø³Øª Ù†Ø´Ø¯Ù‡.")

    client = OpenAI(base_url="https://api.avalai.ir/v1", api_key=api_key)

    tmp_path = Path("/tmp") / filename
    tmp_path.write_bytes(file_bytes)

    try:
        with open(tmp_path, "rb") as f:
            t = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="text",
                language="fa",
            )
        return str(t)
    finally:
        try:
            tmp_path.unlink(missing_ok=True)
        except Exception:
            pass

def generate_report(resume_text: str, jd_text: str, interview_asr: str) -> str:
    api_key = os.getenv("AVALAI_API_KEY")
    if not api_key:
        raise RuntimeError("Ú©Ù„ÛŒØ¯ AVALAI_API_KEY Ø¯Ø± Secrets Ø³Øª Ù†Ø´Ø¯Ù‡.")
    client = OpenAI(base_url="https://api.avalai.ir/v1", api_key=api_key)

    SYSTEM = "You are a strict, evidence-based HR evaluator. Be structured, concise, and avoid fluff."

    ASR_NOTE_FA = """
Ù…ØªÙ† Ù…ØµØ§Ø­Ø¨Ù‡ Ø²ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ Ø®Ø§Ù… ØªØ¨Ø¯ÛŒÙ„ Ú¯ÙØªØ§Ø± Ø¨Ù‡ Ù…ØªÙ† (ASR) Ø§Ø³Øª Ùˆ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø´Ø§Ù…Ù„ ØºÙ„Ø· Ø§Ù…Ù„Ø§ÛŒÛŒØŒ
Ø´Ú©Ø³Øª Ú©Ù„Ù…Ø§ØªØŒ ØªÚ©Ø±Ø§Ø±ØŒ ÛŒØ§ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù†Ú¯Ø§Ø±Ø´ÛŒ Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ù†Ø§Ø´ÛŒ Ø§Ø² Ø³ÛŒØ³ØªÙ… ASR Ø§Ø³Øª Ù†Ù‡ ÙØ±Ø¯ Ù…ØµØ§Ø­Ø¨Ù‡â€ŒØ´ÙˆÙ†Ø¯Ù‡.
Ú©ÛŒÙÛŒØª Ø²Ø¨Ø§Ù†/Ø§Ù…Ù„Ø§ Ø±Ø§ Ù…Ø¹ÛŒØ§Ø± Ù‚Ø¶Ø§ÙˆØª Ù‚Ø±Ø§Ø± Ù†Ø¯Ù‡. Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ø±Ø§ Ù†ÙˆÛŒØ² ÙØ±Ø¶ Ú©Ù†.
"""

    FORMAT_SPEC = f"""
Ú¯Ø²Ø§Ø±Ø´ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§ â€” Ù†Ø³Ø®Ù‡ ÛŒÚ©â€ŒØµÙØ­Ù‡â€ŒØ§ÛŒ (ÙØ§Ø±Ø³ÛŒ)

Ù†Ø§Ù… Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§: (Ø§Ø² Ø±Ø²ÙˆÙ…Ù‡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†Ø› Ø§Ú¯Ø± Ù†Ø¨ÙˆØ¯ "Ù†Ø§Ù…Ø´Ø®Øµ")
Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„: (Ø§Ø² JD Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†Ø› Ø§Ú¯Ø± Ù†Ø¨ÙˆØ¯ "Ù†Ø§Ù…Ø´Ø®Øµ")
ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´: {date.today().strftime("%Y-%m-%d")}
Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø±Ø±Ø³ÛŒ: Ø±Ø²ÙˆÙ…Ù‡ + ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù…ØµØ§Ø­Ø¨Ù‡ (Ø®Ø±ÙˆØ¬ÛŒ ASR)

1) Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ
- Ø§Ù…ØªÛŒØ§Ø² ØªÙ†Ø§Ø³Ø¨ Ú©Ù„ÛŒ (Fit Score): XX/100 | Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: Ú©Ù…/Ù…ØªÙˆØ³Ø·/Ø¨Ø§Ù„Ø§
- Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Yes / No / Maybe (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ù…Ø´Ø±ÙˆØ·)
- Ú†Ø±Ø§ Ù…Ø«Ø¨ØªØŸ (Û²-Û³ Ø¬Ù…Ù„Ù‡)
- Ø±ÛŒØ³Ú© Ø§ØµÙ„ÛŒ: (Û±-Û² Ø¬Ù…Ù„Ù‡)

2) Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ú©Ù„ÛŒØ¯ÛŒ (Strengths)
3) Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù / Ø±ÛŒØ³Ú©â€ŒÙ‡Ø§ (Weaknesses & Risks)

4) ØªØ­Ù„ÛŒÙ„ ØªÙ†Ø§Ø³Ø¨ Ù…Ù‡Ø§Ø±ØªÛŒ (Resume vs JD)
- Must-have Ù‡Ø§ (Ú©Ù„ÛŒØ¯ÛŒ): Ø¬Ø¯ÙˆÙ„ Markdown Ø¯Ù‚ÛŒÙ‚ Ø¨Ø§ 3 Ø³ØªÙˆÙ†:
| Ù†ÛŒØ§Ø² Ø´ØºÙ„ÛŒ | Ø´ÙˆØ§Ù‡Ø¯ Ø§Ø² Ø±Ø²ÙˆÙ…Ù‡/Ù…ØµØ§Ø­Ø¨Ù‡ | Ù…ÛŒØ²Ø§Ù† ØªØ·Ø§Ø¨Ù‚ |
|---|---|---|
| ... | ... | Ù¾Ø§ÛŒÛŒÙ†/Ù…ØªÙˆØ³Ø·/Ø¨Ø§Ù„Ø§ |

- Ø´Ú©Ø§Ùâ€ŒÙ‡Ø§ (Gaps): 2 ØªØ§ 4 Ù…ÙˆØ±Ø¯ Ø¨Ø§ Impact: Low/Medium/High

5) ØªØ­Ù„ÛŒÙ„ Ù…ØµØ§Ø­Ø¨Ù‡ (Ø³Ø¨Ú© Ú©Ø§Ø±ÛŒ Ø§Ø² Ù„Ø­Ù† Ùˆ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§)
- Ø³Ø§Ø®ØªØ§Ø±/Ø´ÙØ§ÙÛŒØª/Ù…Ø§Ù„Ú©ÛŒØª/Ø±ÛŒØ³Ú©â€ŒÙ‡Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø·ÛŒ + Ø¯Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡
- 2 Quote Ú©ÙˆØªØ§Ù‡

6) Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø§Ø¯Ø¹Ø§Ù‡Ø§ (Resume vs Interview)
7) Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ± Ø¨Ø¹Ø¯ (Ø³ÙˆØ§Ù„Ø§Øª Ù‡Ø¯ÙÙ…Ù†Ø¯)
8) Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ

Ù…Ø¨Ù†Ø§ÛŒ Fit Score Ø±Ø§ ØµØ±ÛŒØ­ Ùˆ Ø³Ø§Ø¯Ù‡ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡:
- 4 Ù…Ø¹ÛŒØ§Ø±: Ø¯Ø±Ú© Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©ØŒ ØªØ­Ù„ÛŒÙ„ Ùˆ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒØŒ Ù†Ú¯Ø§Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒØŒ Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙØªØ§Ø±ÛŒ
- Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…Ø¹ÛŒØ§Ø±: Ø§Ù…ØªÛŒØ§Ø² + Ø´ÙˆØ§Ù‡Ø¯ + Ø¯Ù„ÛŒÙ„
"""

    prompt = f"""
{FORMAT_SPEC}

Ù‚ÙˆØ§Ù†ÛŒÙ†:
- ÙÙ‚Ø· Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ù‡ ÙˆØ±ÙˆØ¯ÛŒ Ù‚Ø¶Ø§ÙˆØª Ú©Ù†: JDØŒ Ø±Ø²ÙˆÙ…Ù‡ØŒ Ù…ØªÙ† Ù…ØµØ§Ø­Ø¨Ù‡
- Ù…ØªÙ† Ù…ØµØ§Ø­Ø¨Ù‡ ASR Ø®Ø§Ù… Ø§Ø³Øª: {ASR_NOTE_FA}
- Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ù†Ø¯Ø§Ø±ÛŒÙ…: "Ù†Ø§Ù…Ø´Ø®Øµ/ÛŒØ§ÙØª Ù†Ø´Ø¯"
- Ø§Ø² Ù‚Ø·Ø¹ÛŒØªâ€ŒÙ†Ù…Ø§ÛŒÛŒ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³Ø§Ù†Ù‡ Ù¾Ø±Ù‡ÛŒØ² Ú©Ù†Ø› Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø¨ÛŒØ§Ù† Ú©Ù†.

[JD]
{jd_text}

[RESUME]
{resume_text}

[INTERVIEW_ASR]
{interview_asr}
"""

    resp = client.chat.completions.create(
        model=os.getenv("AVALAI_TEXT_MODEL", "gpt-4o-mini"),
        messages=[
            {"role": "system", "content": SYSTEM},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
    )
    return resp.choices[0].message.content

# =========================
# Word export: convert ALL markdown tables to real Word tables
# =========================
def report_to_docx_bytes(report_text: str) -> bytes:
    from docx import Document
    from docx.shared import Pt
    from docx.enum.text import WD_ALIGN_PARAGRAPH

    doc = Document()

    def add_rtl_paragraph(text, bold=False, size=11):
        p = doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.RIGHT
        run = p.add_run(text)
        run.bold = bold
        run.font.size = Pt(size)

    add_rtl_paragraph("Ú¯Ø²Ø§Ø±Ø´ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§ â€” Ù†Ø³Ø®Ù‡ ÛŒÚ©â€ŒØµÙØ­Ù‡â€ŒØ§ÛŒ", bold=True, size=14)
    doc.add_paragraph("")

    lines = report_text.splitlines()
    i = 0
    while i < len(lines):
        line = lines[i].strip()

        if not line:
            doc.add_paragraph("")
            i += 1
            continue

        # detect markdown table start
        if is_md_table_line(line) and i + 1 < len(lines) and is_md_separator(lines[i+1]):
            table_block = [line, lines[i+1].strip()]
            j = i + 2
            while j < len(lines) and is_md_table_line(lines[j].strip()):
                table_block.append(lines[j].strip())
                j += 1

            headers, rows = parse_md_table(table_block)

            t = doc.add_table(rows=1, cols=len(headers))
            t.style = "Table Grid"

            # header row
            hdr_cells = t.rows[0].cells
            for c_idx, h in enumerate(headers):
                hdr_cells[c_idx].text = h

            # rows
            for r in rows:
                row_cells = t.add_row().cells
                for c_idx, val in enumerate(r):
                    row_cells[c_idx].text = val

            # align all cells right and set font size
            for row in t.rows:
                for cell in row.cells:
                    for p in cell.paragraphs:
                        p.alignment = WD_ALIGN_PARAGRAPH.RIGHT
                        for run in p.runs:
                            run.font.size = Pt(10)

            doc.add_paragraph("")
            i = j
            continue

        # headings/meta
        is_section = any(line.startswith(f"{k})") for k in range(1, 9))
        is_meta = line.startswith("Ù†Ø§Ù… Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§") or line.startswith("Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„") or line.startswith("ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´") or line.startswith("Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø±Ø±Ø³ÛŒ")

        if is_section:
            add_rtl_paragraph(line, bold=True, size=12)
        elif is_meta:
            add_rtl_paragraph(line, bold=True, size=11)
        else:
            add_rtl_paragraph(line, bold=False, size=11)

        i += 1

    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# =========================
# UI
# =========================
st.markdown("""
<div class="rtl">
  <h1>ğŸ§  Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ø§Ù†Ø¯ÛŒØ¯Ø§</h1>
  <div class="small">Ø¢Ù¾Ù„ÙˆØ¯ Û³ ÙØ§ÛŒÙ„ â†’ ØªØ¨Ø¯ÛŒÙ„ Ú¯ÙØªØ§Ø± Ø¨Ù‡ Ù…ØªÙ† â†’ Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ â†’ Ø®Ø±ÙˆØ¬ÛŒ Word</div>
</div>
<hr/>
""", unsafe_allow_html=True)

left, right = st.columns([1, 1], gap="large")

with left:
    st.markdown('<div class="card rtl">', unsafe_allow_html=True)
    st.subheader("ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§")
    audio = st.file_uploader("ÙØ§ÛŒÙ„ ØµÙˆØª/ÙˆÛŒØ¯Ø¦Ùˆ Ù…ØµØ§Ø­Ø¨Ù‡", type=["mp3","wav","m4a","mp4","mpeg","mpga","ogg","oga","webm","flac"])
    resume = st.file_uploader("Ø±Ø²ÙˆÙ…Ù‡ (pdf/docx/txt)", type=["pdf","docx","txt"])
    jd = st.file_uploader("Ø¢Ú¯Ù‡ÛŒ Ø´ØºÙ„ÛŒ (pdf/docx/txt)", type=["pdf","docx","txt"])
    st.markdown('<div class="small">Ù†Ú©ØªÙ‡: Ù…ØªÙ† Ù…ØµØ§Ø­Ø¨Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø®Ø§Ù… ASR Ø§Ø³ØªØ› ØºÙ„Ø·â€ŒÙ‡Ø§ÛŒ Ù†ÙˆØ´ØªØ§Ø±ÛŒ Ù…Ø¹ÛŒØ§Ø± Ù‚Ø¶Ø§ÙˆØª Ù†ÛŒØ³Øª.</div>', unsafe_allow_html=True)
    run = st.button("âœ… ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´", use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)

with right:
    st.markdown('<div class="card rtl">', unsafe_allow_html=True)
    st.subheader("Ø®Ø±ÙˆØ¬ÛŒ")
    st.markdown('<div class="small">Ú¯Ø²Ø§Ø±Ø´ Ø¨Ù‡â€ŒØµÙˆØ±Øª HTML Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ Word Ø¬Ø¯ÙˆÙ„â€ŒØ¯Ø§Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯.</div>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)

if run:
    if not (audio and resume and jd):
        st.error("Ù‡Ø± Û³ ÙØ§ÛŒÙ„ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†.")
        st.stop()

    progress = st.progress(0, text="Ø´Ø±ÙˆØ¹...")

    try:
        progress.progress(15, text="ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†...")
        interview_text = transcribe_audio_bytes(audio.getvalue(), audio.name)

        progress.progress(40, text="Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø±Ø²ÙˆÙ…Ù‡ Ùˆ Ø¢Ú¯Ù‡ÛŒ Ø´ØºÙ„ÛŒ...")
        resume_text = extract_text_from_upload(resume)
        jd_text = extract_text_from_upload(jd)

        progress.progress(70, text="ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ...")
        report_text = generate_report(resume_text, jd_text, interview_text)

        progress.progress(90, text="Ø³Ø§Ø®Øª ÙØ§ÛŒÙ„ Word Ø¬Ø¯ÙˆÙ„â€ŒØ¯Ø§Ø±...")
        docx_bytes = report_to_docx_bytes(report_text)

        progress.progress(100, text="Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ âœ…")
        st.markdown("<hr/>", unsafe_allow_html=True)

        # Display as HTML with RTL/LTR fixes + table borders
        st.markdown(markdown_to_html_with_tables(report_text), unsafe_allow_html=True)

        st.download_button(
            "â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú¯Ø²Ø§Ø±Ø´ Word (Ø¬Ø¯ÙˆÙ„â€ŒØ¯Ø§Ø±)",
            data=docx_bytes,
            file_name="candidate_report.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            use_container_width=True
        )

    except Exception as e:
        st.error(f"Ø®Ø·Ø§: {e}")
